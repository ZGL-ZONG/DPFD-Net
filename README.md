#ðŸŒˆâ€ŽTitle<br/> DPFD-Net: a dual-path focus diffusion network for infrared small target detection

#ðŸŒˆâ€ŽDescription <br/>

    This project provides a complete infrared visual analysis framework, which integrates the processing, training and evaluation functions of two public datasets, HIT-UAV ( High-altitude UAV Infrared Thermal Imaging )   and M3FD-i ( Multi-modal Face Recognition Infrared Subset ). The framework aims to simplify the research process of infrared target detection and provide a reproducible benchmark implementation for academia.

#ðŸŒˆâ€ŽDataset Information<br/>
   1. HIT-UAV Dataset
    Download URL: https://datasetninja.com/hit-uav
   2. M3FD-i Dataset
    Download URL:[Biendata Platform](https://github.com/dlut-dimt/TarDAL)<br/>
   
#ðŸŒˆ Code Information.<br/>
This project is built and extended based on the Ultralytics YOLOv8 framework, primarily for infrared object detection tasks. The core code is organized as follows:<br/>

Main Module Directories:<br/>
models/: Contains model definitions, network architectures, and related configuration and construction logic.<br/>

data/: The data processing module, responsible for data loading, augmentation, dataset construction, and management.<br/>

utils/: A collection of utility functions, including logging, metric calculation, and general helper functions.<br/>

nn/: Basic neural network modules, layers, and functional blocks.<br/>

trackers/: (If applicable) Target tracking-related algorithms and implementations.<br/>

engine/: The core engine for training, validation, and inference pipelines.<br/>

hub/: Functionality for model uploading, downloading, and integration.<br/>

cfg/: Configuration file directory, containing YAML configuration files for models, training, data, and other parameters.<br/>

Core Root Directory Files:<br/>
__init__.py: The package initialization file, defining the module's public interface, version information, etc.<br/>

Cache and Build:<br/>
__pycache__/: Python bytecode cache directory, automatically generated by the interpreter to speed up module loading. It is typically excluded from version control.<br/>

#ðŸŒˆâ€ŽUsage Instructions .<br/>
    Environmental configuration and use steps <br/>
    Step 1 : Installation dependency<br/>
       # 1.Cloning project code 
           git clone [ https://github.com/ZGL-ZONG/DPFD-Net.git<br/> ] 
           cd DPFD-Net<br/>
       # 2. Create and activate a virtual environment ( optional, but recommended ) <br/>
           conda create -n ir _ detection python = 3.10.14 -y <br/>
           conda activate ir _ detection <br/>
       # 3. Install PyTorch ( adjusted for your CUDA version, 12.1 here )<br/> 
           pip install torch = = 2.2.2 torchvision = = 0.17.2-index-url https://download.pytorch.org/whl/cu121 <br/>
       # 4.Installation project other dependencies <br/>
           pip install-r requirements.txt<br/>
    Step 2 : Prepare the data 
       This framework supports HIT-UAV and M3FD-i datasets. Please place the folder according to the following structure : <br/>     
        â”œâ”€â”€ data/<br/>
        â”‚   â”œâ”€â”€ hit-uav/                   # HIT-UAV data set root directory<br/>
        â”‚   â”‚   â”œâ”€â”€ images/<br/>
        â”‚   â”‚   â”‚   â”œâ”€â”€ train/             # Placing training set pictures<br/>
        â”‚   â”‚   â”‚   â””â”€â”€ val/               # Place the verification set picture<br/>
        â”‚   â”‚   â”‚   â””â”€â”€ test/<br/>
        â”‚   â”‚   â””â”€â”€ labels/<br/>
        â”‚   â”‚       â”œâ”€â”€ train/             # Placing training set labels(.txtï¼‰<br/>
        â”‚   â”‚       â””â”€â”€ val/               # Place the validation set label(.txt)<br/>
        â”‚   â”‚       â””â”€â”€ test/<br/>
        â”‚   â””â”€â”€ m3fd-i/                    # M3FD-i dataset root directory<br/>
        â”‚       â”œâ”€â”€ images/<br/>
        â”‚       â”‚   â”œâ”€â”€ train/<br/>
        â”‚       â”‚   â””â”€â”€ val/<br/>
                    â””â”€â”€ test/<br/>
        â”‚       â””â”€â”€ labels/<br/>
        â”‚           â”œâ”€â”€ train/<br/>
        â”‚           â””â”€â”€ val/<br/>
                    â””â”€â”€ test/<br/>


   Step 3 : Training the model <br/>
      We provide a configuration file (.yaml ) for two data sets, which is located in the configs / directory. Start the training with the following command :<br/>

      python scripts/train.py --data configs/data/hit-uav.yaml  --epochs 300 --imgsz 640 --batch 8 --name hit-uav<br/>

      python scripts/train.py --data configs/data/m3fd-i.yaml  --epochs 300 --imgsz 640 --batch 8 --name m3fd-i<br/>

  Step 4 : Testing and reasoning <br/>
  # Reasoning for a single picture<br/>
     python scripts/infer.py --weights runs/train/hit-uav/weights/best.pt --source data/hit-uav/images/val/000001.jpg --conf 0.25<br/>

  # Reasons the entire validation set and saves the results<br/>
     python scripts/infer.py --weights runs/train/m3fd-i/weights/best.pt --source data/m3fd-i/images/val/ --save-txt --save-conf<br/>
  
   After the training is completed, the best weight ( best.pt ) is used to infer a single picture, video, or entire folder.<br/>
  Step 5 : Evaluation results<br/> 
     We provide a standardized evaluation script for calculating key indicators such as mAP, Precision, and Recall on the verification set.<br/>
     
     python train.py<br/>
     
     python val.py<br/>
     
#ðŸŒˆâ€ŽRequirements.txt <br/>
   matplotlib>=3.3.0<br/>
   numpy>=1.22.2 # pinned by Snyk to avoid a vulnerability<br/>
   opencv-python>=4.6.0<br/>
   pillow>=7.1.2<br/>
   pyyaml>=5.3.1<br/>
   requests>=2.23.0<br/>
   scipy>=1.4.1<br/>
   torch>=1.8.0<br/>
   torchvision>=0.9.0<br/>
   tqdm>=4.64.0<br/>




